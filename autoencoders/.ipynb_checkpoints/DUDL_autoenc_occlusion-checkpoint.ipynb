{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bhWV8oes-wKR"
   },
   "source": [
    "# COURSE: A deep understanding of deep learning\n",
    "## SECTION: Autoencoders\n",
    "### LECTURE: AEs for occlusion\n",
    "#### TEACHER: Mike X Cohen, sincxpress.com\n",
    "##### COURSE URL: udemy.com/course/deeplearning_x/?couponCode=202212"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "YeuAheYyhdZw"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/f2/gq8xgm9x491cqwtct_tgpy0h0000gn/T/ipykernel_64245/2850606974.py:12: DeprecationWarning: `set_matplotlib_formats` is deprecated since IPython 7.23, directly use `matplotlib_inline.backend_inline.set_matplotlib_formats()`\n",
      "  display.set_matplotlib_formats('svg')\n"
     ]
    }
   ],
   "source": [
    "# import libraries\n",
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "import copy\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython import display\n",
    "display.set_matplotlib_formats('svg')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0HOkOefftqyg"
   },
   "source": [
    "# Import and process the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "MU7rvmWuhjud"
   },
   "outputs": [],
   "source": [
    "# import dataset (comes with colab!)\n",
    "data = np.loadtxt(open('mnist_train_small.csv','rb'),delimiter=',')\n",
    "\n",
    "# don't need labels!\n",
    "data = data[:,1:]\n",
    "\n",
    "# normalize the data to a range of [0 1]\n",
    "dataNorm = data / np.max(data)\n",
    "\n",
    "# convert to tensor\n",
    "dataT = torch.tensor( dataNorm ).float()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jiXtRaHE8EGh"
   },
   "source": [
    "# Demonstration of implementing occlusion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "O4978R7R8DBJ"
   },
   "outputs": [
    {
     "data": {
      "image/svg+xml": [
       "<?xml version=\"1.0\" encoding=\"utf-8\" standalone=\"no\"?>\n",
       "<!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\"\n",
       "  \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\">\n",
       "<svg xmlns:xlink=\"http://www.w3.org/1999/xlink\" width=\"460.8pt\" height=\"232.427216pt\" viewBox=\"0 0 460.8 232.427216\" xmlns=\"http://www.w3.org/2000/svg\" version=\"1.1\">\n",
       " <metadata>\n",
       "  <rdf:RDF xmlns:dc=\"http://purl.org/dc/elements/1.1/\" xmlns:cc=\"http://creativecommons.org/ns#\" xmlns:rdf=\"http://www.w3.org/1999/02/22-rdf-syntax-ns#\">\n",
       "   <cc:Work>\n",
       "    <dc:type rdf:resource=\"http://purl.org/dc/dcmitype/StillImage\"/>\n",
       "    <dc:date>2023-01-30T22:25:34.570674</dc:date>\n",
       "    <dc:format>image/svg+xml</dc:format>\n",
       "    <dc:creator>\n",
       "     <cc:Agent>\n",
       "      <dc:title>Matplotlib v3.6.0, https://matplotlib.org/</dc:title>\n",
       "     </cc:Agent>\n",
       "    </dc:creator>\n",
       "   </cc:Work>\n",
       "  </rdf:RDF>\n",
       " </metadata>\n",
       " <defs>\n",
       "  <style type=\"text/css\">*{stroke-linejoin: round; stroke-linecap: butt}</style>\n",
       " </defs>\n",
       " <g id=\"figure_1\">\n",
       "  <g id=\"patch_1\">\n",
       "   <path d=\"M 0 232.427216 \n",
       "L 460.8 232.427216 \n",
       "L 460.8 0 \n",
       "L 0 0 \n",
       "z\n",
       "\" style=\"fill: #ffffff\"/>\n",
       "  </g>\n",
       "  <g id=\"axes_1\">\n",
       "   <g clip-path=\"url(#p72050a780a)\">\n",
       "    <image xlink:href=\"data:image/png;base64,\n",
       "iVBORw0KGgoAAAANSUhEUgAAARoAAAEaCAYAAADOs5i6AAAGJklEQVR4nO3cIWgVagPH4bOPwRiCzJUFk8GmgmJT0CWx2QSx6IpiFIvZZhYxmcwGi6IWYc00i2GgBsvACYoIiu62C1+48ML225n3Pk/+w3nD4ccb3nNmJpPJ1gQg9L9pHwD49xMaICc0QE5ogJzQADmhAXJCA+SEBsgJDZATGiAnNEBOaICc0AA5oQFyQgPkhAbICQ2QExogJzRAbnbaB4Bnz54N7dbX14d2N27c2M5xCLjRADmhAXJCA+SEBsgJDZATGiAnNEBOaICc0AA5L4PJLCwsDO2Wl5eHdouLi9s4DdPkRgPkhAbICQ2QExogJzRATmiAnNAAOaEBckID5LwMJjMzMzO0m50d+xqurKxs5zhMkRsNkBMaICc0QE5ogJzQADmhAXJCA+SEBsgJDZDzMpjM4cOHh3ajL4jX1ta2cxymyI0GyAkNkBMaICc0QE5ogJzQADmhAXJCA+SEBsh5GUzm6tWrQ7utra34JEybGw2QExogJzRATmiAnNAAOaEBckID5IQGyAkNkBMaIOcnCGQ2NzenfQT2CDcaICc0QE5ogJzQADmhAXJCA+SEBsgJDZATGiDnZTCZxcXFaR+BPcKNBsgJDZATGiAnNEBOaICc0AA5oQFyQgPkhAbIeRlMZmZmZmi3vr4en4Rpc6MBckID5IQGyAkNkBMaICc0QE5ogJzQADmhAXJeBvO3ffv2De0OHTo0tNva2trRHX8uNxogJzRATmiAnNAAOaEBckID5IQGyAkNkBMaIOdl8B/s9OnTQ7s7d+4M7Y4fPz60G31B/PPnz6Hd3Nzc0O7gwYNDu48fPw7t2D1uNEBOaICc0AA5oQFyQgPkhAbICQ2QExogJzRAbmYymfjD1j3m5MmTQ7sXL14M7T5//jy0e/ny5dBufn5+aHf+/Pmh3cLCwtDux48fQ7vLly8P7R4/fjy0+/Xr19COf+ZGA+SEBsgJDZATGiAnNEBOaICc0AA5oQFyQgPk/GfwHnT79u2h3eiL3yNHjgztvn37NrQb9eDBg6Hd8vLy0O7SpUtDu1u3bg3tlpaWhnb37t0b2vHP3GiAnNAAOaEBckID5IQGyAkNkBMaICc0QE5ogJyXwbto9L+AL1y4MLS7du3a0G6nX/yO2toa+zvq9+/fD+1ev349tLt48eLQ7vr160O7U6dODe1WV1eHdv9FbjRATmiAnNAAOaEBckID5IQGyAkNkBMaICc0QM7L4D/Y2tratI+wI44ePTqVz71///5UPve/yI0GyAkNkBMaICc0QE5ogJzQADmhAXJCA+SEBsh5GbwHff/+fWj34cOH+CTbs7GxMbRbWlqKT8K0udEAOaEBckID5IQGyAkNkBMaICc0QE5ogJzQADkvg3fRgQMHpn2EXfXmzZuh3ebmZnwSps2NBsgJDZATGiAnNEBOaICc0AA5oQFyQgPkhAbIeRm8i06cODG0m5+f39HdtMzOjn29Pn36NLTbv3//0O7Lly9DO3aPGw2QExogJzRATmiAnNAAOaEBckID5IQGyAkNkPMyeBe9e/duaPf79+/4JLvj6dOnQ7tHjx4N7c6cOTO0e/LkydCO3eNGA+SEBsgJDZATGiAnNEBOaICc0AA5oQFyQgPkZiaTyda0D8H/W11dHdptbm4O7VZWVoZ2GxsbQ7tRc3NzQ7tXr14N7d6+fTu0u3LlytDu3/IC+0/gRgPkhAbICQ2QExogJzRATmiAnNAAOaEBckID5IQGyPkJwh507ty5od3NmzeHdnfv3h3aPX/+fGi3086ePTu0e/jw4dDu2LFjQ7uvX78O7dg+NxogJzRATmiAnNAAOaEBckID5IQGyAkNkBMaIOdlMJBzowFyQgPkhAbICQ2QExogJzRATmiAnNAAOaEBckID5IQGyAkNkBMaICc0QE5ogJzQADmhAXJCA+SEBsgJDZATGiAnNEBOaICc0AA5oQFyQgPkhAbICQ2QExogJzRATmiAnNAAOaEBckID5IQGyAkNkBMaICc0QE5ogJzQADmhAXJCA+SEBsgJDZATGiAnNEBOaICc0AA5oQFyQgPkhAbICQ2QExogJzRATmiAnNAAOaEBckID5IQGyP0FUROjLyIsbFsAAAAASUVORK5CYII=\" id=\"imagea893a24127\" transform=\"scale(1 -1) translate(0 -203.04)\" x=\"7.2\" y=\"-22.187216\" width=\"203.04\" height=\"203.04\"/>\n",
       "   </g>\n",
       "   <g id=\"text_1\">\n",
       "    <!-- Original image -->\n",
       "    <g transform=\"translate(64.579858 16.318125) scale(0.12 -0.12)\">\n",
       "     <defs>\n",
       "      <path id=\"DejaVuSans-4f\" d=\"M 2522 4238 \n",
       "Q 1834 4238 1429 3725 \n",
       "Q 1025 3213 1025 2328 \n",
       "Q 1025 1447 1429 934 \n",
       "Q 1834 422 2522 422 \n",
       "Q 3209 422 3611 934 \n",
       "Q 4013 1447 4013 2328 \n",
       "Q 4013 3213 3611 3725 \n",
       "Q 3209 4238 2522 4238 \n",
       "z\n",
       "M 2522 4750 \n",
       "Q 3503 4750 4090 4092 \n",
       "Q 4678 3434 4678 2328 \n",
       "Q 4678 1225 4090 567 \n",
       "Q 3503 -91 2522 -91 \n",
       "Q 1538 -91 948 565 \n",
       "Q 359 1222 359 2328 \n",
       "Q 359 3434 948 4092 \n",
       "Q 1538 4750 2522 4750 \n",
       "z\n",
       "\" transform=\"scale(0.015625)\"/>\n",
       "      <path id=\"DejaVuSans-72\" d=\"M 2631 2963 \n",
       "Q 2534 3019 2420 3045 \n",
       "Q 2306 3072 2169 3072 \n",
       "Q 1681 3072 1420 2755 \n",
       "Q 1159 2438 1159 1844 \n",
       "L 1159 0 \n",
       "L 581 0 \n",
       "L 581 3500 \n",
       "L 1159 3500 \n",
       "L 1159 2956 \n",
       "Q 1341 3275 1631 3429 \n",
       "Q 1922 3584 2338 3584 \n",
       "Q 2397 3584 2469 3576 \n",
       "Q 2541 3569 2628 3553 \n",
       "L 2631 2963 \n",
       "z\n",
       "\" transform=\"scale(0.015625)\"/>\n",
       "      <path id=\"DejaVuSans-69\" d=\"M 603 3500 \n",
       "L 1178 3500 \n",
       "L 1178 0 \n",
       "L 603 0 \n",
       "L 603 3500 \n",
       "z\n",
       "M 603 4863 \n",
       "L 1178 4863 \n",
       "L 1178 4134 \n",
       "L 603 4134 \n",
       "L 603 4863 \n",
       "z\n",
       "\" transform=\"scale(0.015625)\"/>\n",
       "      <path id=\"DejaVuSans-67\" d=\"M 2906 1791 \n",
       "Q 2906 2416 2648 2759 \n",
       "Q 2391 3103 1925 3103 \n",
       "Q 1463 3103 1205 2759 \n",
       "Q 947 2416 947 1791 \n",
       "Q 947 1169 1205 825 \n",
       "Q 1463 481 1925 481 \n",
       "Q 2391 481 2648 825 \n",
       "Q 2906 1169 2906 1791 \n",
       "z\n",
       "M 3481 434 \n",
       "Q 3481 -459 3084 -895 \n",
       "Q 2688 -1331 1869 -1331 \n",
       "Q 1566 -1331 1297 -1286 \n",
       "Q 1028 -1241 775 -1147 \n",
       "L 775 -588 \n",
       "Q 1028 -725 1275 -790 \n",
       "Q 1522 -856 1778 -856 \n",
       "Q 2344 -856 2625 -561 \n",
       "Q 2906 -266 2906 331 \n",
       "L 2906 616 \n",
       "Q 2728 306 2450 153 \n",
       "Q 2172 0 1784 0 \n",
       "Q 1141 0 747 490 \n",
       "Q 353 981 353 1791 \n",
       "Q 353 2603 747 3093 \n",
       "Q 1141 3584 1784 3584 \n",
       "Q 2172 3584 2450 3431 \n",
       "Q 2728 3278 2906 2969 \n",
       "L 2906 3500 \n",
       "L 3481 3500 \n",
       "L 3481 434 \n",
       "z\n",
       "\" transform=\"scale(0.015625)\"/>\n",
       "      <path id=\"DejaVuSans-6e\" d=\"M 3513 2113 \n",
       "L 3513 0 \n",
       "L 2938 0 \n",
       "L 2938 2094 \n",
       "Q 2938 2591 2744 2837 \n",
       "Q 2550 3084 2163 3084 \n",
       "Q 1697 3084 1428 2787 \n",
       "Q 1159 2491 1159 1978 \n",
       "L 1159 0 \n",
       "L 581 0 \n",
       "L 581 3500 \n",
       "L 1159 3500 \n",
       "L 1159 2956 \n",
       "Q 1366 3272 1645 3428 \n",
       "Q 1925 3584 2291 3584 \n",
       "Q 2894 3584 3203 3211 \n",
       "Q 3513 2838 3513 2113 \n",
       "z\n",
       "\" transform=\"scale(0.015625)\"/>\n",
       "      <path id=\"DejaVuSans-61\" d=\"M 2194 1759 \n",
       "Q 1497 1759 1228 1600 \n",
       "Q 959 1441 959 1056 \n",
       "Q 959 750 1161 570 \n",
       "Q 1363 391 1709 391 \n",
       "Q 2188 391 2477 730 \n",
       "Q 2766 1069 2766 1631 \n",
       "L 2766 1759 \n",
       "L 2194 1759 \n",
       "z\n",
       "M 3341 1997 \n",
       "L 3341 0 \n",
       "L 2766 0 \n",
       "L 2766 531 \n",
       "Q 2569 213 2275 61 \n",
       "Q 1981 -91 1556 -91 \n",
       "Q 1019 -91 701 211 \n",
       "Q 384 513 384 1019 \n",
       "Q 384 1609 779 1909 \n",
       "Q 1175 2209 1959 2209 \n",
       "L 2766 2209 \n",
       "L 2766 2266 \n",
       "Q 2766 2663 2505 2880 \n",
       "Q 2244 3097 1772 3097 \n",
       "Q 1472 3097 1187 3025 \n",
       "Q 903 2953 641 2809 \n",
       "L 641 3341 \n",
       "Q 956 3463 1253 3523 \n",
       "Q 1550 3584 1831 3584 \n",
       "Q 2591 3584 2966 3190 \n",
       "Q 3341 2797 3341 1997 \n",
       "z\n",
       "\" transform=\"scale(0.015625)\"/>\n",
       "      <path id=\"DejaVuSans-6c\" d=\"M 603 4863 \n",
       "L 1178 4863 \n",
       "L 1178 0 \n",
       "L 603 0 \n",
       "L 603 4863 \n",
       "z\n",
       "\" transform=\"scale(0.015625)\"/>\n",
       "      <path id=\"DejaVuSans-20\" transform=\"scale(0.015625)\"/>\n",
       "      <path id=\"DejaVuSans-6d\" d=\"M 3328 2828 \n",
       "Q 3544 3216 3844 3400 \n",
       "Q 4144 3584 4550 3584 \n",
       "Q 5097 3584 5394 3201 \n",
       "Q 5691 2819 5691 2113 \n",
       "L 5691 0 \n",
       "L 5113 0 \n",
       "L 5113 2094 \n",
       "Q 5113 2597 4934 2840 \n",
       "Q 4756 3084 4391 3084 \n",
       "Q 3944 3084 3684 2787 \n",
       "Q 3425 2491 3425 1978 \n",
       "L 3425 0 \n",
       "L 2847 0 \n",
       "L 2847 2094 \n",
       "Q 2847 2600 2669 2842 \n",
       "Q 2491 3084 2119 3084 \n",
       "Q 1678 3084 1418 2786 \n",
       "Q 1159 2488 1159 1978 \n",
       "L 1159 0 \n",
       "L 581 0 \n",
       "L 581 3500 \n",
       "L 1159 3500 \n",
       "L 1159 2956 \n",
       "Q 1356 3278 1631 3431 \n",
       "Q 1906 3584 2284 3584 \n",
       "Q 2666 3584 2933 3390 \n",
       "Q 3200 3197 3328 2828 \n",
       "z\n",
       "\" transform=\"scale(0.015625)\"/>\n",
       "      <path id=\"DejaVuSans-65\" d=\"M 3597 1894 \n",
       "L 3597 1613 \n",
       "L 953 1613 \n",
       "Q 991 1019 1311 708 \n",
       "Q 1631 397 2203 397 \n",
       "Q 2534 397 2845 478 \n",
       "Q 3156 559 3463 722 \n",
       "L 3463 178 \n",
       "Q 3153 47 2828 -22 \n",
       "Q 2503 -91 2169 -91 \n",
       "Q 1331 -91 842 396 \n",
       "Q 353 884 353 1716 \n",
       "Q 353 2575 817 3079 \n",
       "Q 1281 3584 2069 3584 \n",
       "Q 2775 3584 3186 3129 \n",
       "Q 3597 2675 3597 1894 \n",
       "z\n",
       "M 3022 2063 \n",
       "Q 3016 2534 2758 2815 \n",
       "Q 2500 3097 2075 3097 \n",
       "Q 1594 3097 1305 2825 \n",
       "Q 1016 2553 972 2059 \n",
       "L 3022 2063 \n",
       "z\n",
       "\" transform=\"scale(0.015625)\"/>\n",
       "     </defs>\n",
       "     <use xlink:href=\"#DejaVuSans-4f\"/>\n",
       "     <use xlink:href=\"#DejaVuSans-72\" x=\"78.710938\"/>\n",
       "     <use xlink:href=\"#DejaVuSans-69\" x=\"119.824219\"/>\n",
       "     <use xlink:href=\"#DejaVuSans-67\" x=\"147.607422\"/>\n",
       "     <use xlink:href=\"#DejaVuSans-69\" x=\"211.083984\"/>\n",
       "     <use xlink:href=\"#DejaVuSans-6e\" x=\"238.867188\"/>\n",
       "     <use xlink:href=\"#DejaVuSans-61\" x=\"302.246094\"/>\n",
       "     <use xlink:href=\"#DejaVuSans-6c\" x=\"363.525391\"/>\n",
       "     <use xlink:href=\"#DejaVuSans-20\" x=\"391.308594\"/>\n",
       "     <use xlink:href=\"#DejaVuSans-69\" x=\"423.095703\"/>\n",
       "     <use xlink:href=\"#DejaVuSans-6d\" x=\"450.878906\"/>\n",
       "     <use xlink:href=\"#DejaVuSans-61\" x=\"548.291016\"/>\n",
       "     <use xlink:href=\"#DejaVuSans-67\" x=\"609.570312\"/>\n",
       "     <use xlink:href=\"#DejaVuSans-65\" x=\"673.046875\"/>\n",
       "    </g>\n",
       "   </g>\n",
       "  </g>\n",
       "  <g id=\"axes_2\">\n",
       "   <g clip-path=\"url(#p746cf361df)\">\n",
       "    <image xlink:href=\"data:image/png;base64,\n",
       "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\" id=\"image9be8d85d05\" transform=\"scale(1 -1) translate(0 -203.04)\" x=\"250.690909\" y=\"-22.187216\" width=\"203.04\" height=\"203.04\"/>\n",
       "   </g>\n",
       "   <g id=\"text_2\">\n",
       "    <!-- Occluded image -->\n",
       "    <g transform=\"translate(303.448892 16.318125) scale(0.12 -0.12)\">\n",
       "     <defs>\n",
       "      <path id=\"DejaVuSans-63\" d=\"M 3122 3366 \n",
       "L 3122 2828 \n",
       "Q 2878 2963 2633 3030 \n",
       "Q 2388 3097 2138 3097 \n",
       "Q 1578 3097 1268 2742 \n",
       "Q 959 2388 959 1747 \n",
       "Q 959 1106 1268 751 \n",
       "Q 1578 397 2138 397 \n",
       "Q 2388 397 2633 464 \n",
       "Q 2878 531 3122 666 \n",
       "L 3122 134 \n",
       "Q 2881 22 2623 -34 \n",
       "Q 2366 -91 2075 -91 \n",
       "Q 1284 -91 818 406 \n",
       "Q 353 903 353 1747 \n",
       "Q 353 2603 823 3093 \n",
       "Q 1294 3584 2113 3584 \n",
       "Q 2378 3584 2631 3529 \n",
       "Q 2884 3475 3122 3366 \n",
       "z\n",
       "\" transform=\"scale(0.015625)\"/>\n",
       "      <path id=\"DejaVuSans-75\" d=\"M 544 1381 \n",
       "L 544 3500 \n",
       "L 1119 3500 \n",
       "L 1119 1403 \n",
       "Q 1119 906 1312 657 \n",
       "Q 1506 409 1894 409 \n",
       "Q 2359 409 2629 706 \n",
       "Q 2900 1003 2900 1516 \n",
       "L 2900 3500 \n",
       "L 3475 3500 \n",
       "L 3475 0 \n",
       "L 2900 0 \n",
       "L 2900 538 \n",
       "Q 2691 219 2414 64 \n",
       "Q 2138 -91 1772 -91 \n",
       "Q 1169 -91 856 284 \n",
       "Q 544 659 544 1381 \n",
       "z\n",
       "M 1991 3584 \n",
       "L 1991 3584 \n",
       "z\n",
       "\" transform=\"scale(0.015625)\"/>\n",
       "      <path id=\"DejaVuSans-64\" d=\"M 2906 2969 \n",
       "L 2906 4863 \n",
       "L 3481 4863 \n",
       "L 3481 0 \n",
       "L 2906 0 \n",
       "L 2906 525 \n",
       "Q 2725 213 2448 61 \n",
       "Q 2172 -91 1784 -91 \n",
       "Q 1150 -91 751 415 \n",
       "Q 353 922 353 1747 \n",
       "Q 353 2572 751 3078 \n",
       "Q 1150 3584 1784 3584 \n",
       "Q 2172 3584 2448 3432 \n",
       "Q 2725 3281 2906 2969 \n",
       "z\n",
       "M 947 1747 \n",
       "Q 947 1113 1208 752 \n",
       "Q 1469 391 1925 391 \n",
       "Q 2381 391 2643 752 \n",
       "Q 2906 1113 2906 1747 \n",
       "Q 2906 2381 2643 2742 \n",
       "Q 2381 3103 1925 3103 \n",
       "Q 1469 3103 1208 2742 \n",
       "Q 947 2381 947 1747 \n",
       "z\n",
       "\" transform=\"scale(0.015625)\"/>\n",
       "     </defs>\n",
       "     <use xlink:href=\"#DejaVuSans-4f\"/>\n",
       "     <use xlink:href=\"#DejaVuSans-63\" x=\"78.710938\"/>\n",
       "     <use xlink:href=\"#DejaVuSans-63\" x=\"133.691406\"/>\n",
       "     <use xlink:href=\"#DejaVuSans-6c\" x=\"188.671875\"/>\n",
       "     <use xlink:href=\"#DejaVuSans-75\" x=\"216.455078\"/>\n",
       "     <use xlink:href=\"#DejaVuSans-64\" x=\"279.833984\"/>\n",
       "     <use xlink:href=\"#DejaVuSans-65\" x=\"343.310547\"/>\n",
       "     <use xlink:href=\"#DejaVuSans-64\" x=\"404.833984\"/>\n",
       "     <use xlink:href=\"#DejaVuSans-20\" x=\"468.310547\"/>\n",
       "     <use xlink:href=\"#DejaVuSans-69\" x=\"500.097656\"/>\n",
       "     <use xlink:href=\"#DejaVuSans-6d\" x=\"527.880859\"/>\n",
       "     <use xlink:href=\"#DejaVuSans-61\" x=\"625.292969\"/>\n",
       "     <use xlink:href=\"#DejaVuSans-67\" x=\"686.572266\"/>\n",
       "     <use xlink:href=\"#DejaVuSans-65\" x=\"750.048828\"/>\n",
       "    </g>\n",
       "   </g>\n",
       "  </g>\n",
       " </g>\n",
       " <defs>\n",
       "  <clipPath id=\"p72050a780a\">\n",
       "   <rect x=\"7.2\" y=\"22.318125\" width=\"202.909091\" height=\"202.909091\"/>\n",
       "  </clipPath>\n",
       "  <clipPath id=\"p746cf361df\">\n",
       "   <rect x=\"250.690909\" y=\"22.318125\" width=\"202.909091\" height=\"202.909091\"/>\n",
       "  </clipPath>\n",
       " </defs>\n",
       "</svg>\n"
      ],
      "text/plain": [
       "<Figure size 800x500 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# reconstruct a sample as an image\n",
    "\n",
    "img = dataT[12345,:].view(28,28)\n",
    "\n",
    "\n",
    "occluded = copy.deepcopy( img )\n",
    "occluded[10:13,:] = 1\n",
    "\n",
    "fig,ax = plt.subplots(1,2,figsize=(8,5))\n",
    "\n",
    "ax[0].imshow(img,cmap='gray')\n",
    "ax[0].set_title('Original image')\n",
    "ax[0].axis('off')\n",
    "\n",
    "ax[1].imshow(occluded,cmap='gray')\n",
    "ax[1].set_title('Occluded image')\n",
    "ax[1].axis('off')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OK8Opkhgp0bO"
   },
   "source": [
    "# Create the DL model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "JK3OO3tAtZkA"
   },
   "outputs": [],
   "source": [
    "# create a class for the model\n",
    "def createTheMNISTAE():\n",
    "\n",
    "  class aenet(nn.Module):\n",
    "    def __init__(self):\n",
    "      super().__init__()\n",
    "\n",
    "      ### input layer\n",
    "      self.input = nn.Linear(784,128)\n",
    "      \n",
    "      ### encoder layer\n",
    "      self.enc = nn.Linear(128,50)\n",
    "\n",
    "      ### latent layer\n",
    "      self.lat = nn.Linear(50,128)\n",
    "\n",
    "      ### decoder layer\n",
    "      self.dec = nn.Linear(128,784)\n",
    "\n",
    "    # forward pass\n",
    "    def forward(self,x):\n",
    "      x = F.relu( self.input(x) )\n",
    "      x = F.relu( self.enc(x) )\n",
    "      x = F.relu( self.lat(x) )\n",
    "      y = torch.sigmoid( self.dec(x) )\n",
    "      return y\n",
    "  \n",
    "  # create the model instance\n",
    "  net = aenet()\n",
    "  \n",
    "  # loss function\n",
    "  lossfun = nn.MSELoss()\n",
    "\n",
    "  # optimizer\n",
    "  optimizer = torch.optim.Adam(net.parameters(),lr=.001)\n",
    "\n",
    "  return net,lossfun,optimizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dvfGQIRGp0ht"
   },
   "source": [
    "# Create a function that trains the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "IblJo1NCp0kl"
   },
   "outputs": [],
   "source": [
    "def function2trainTheModel():\n",
    "\n",
    "  # number of epochs\n",
    "  numepochs = 5\n",
    "  \n",
    "  # create a new model\n",
    "  net,lossfun,optimizer = createTheMNISTAE()\n",
    "\n",
    "  # initialize losses\n",
    "  losses = []\n",
    "\n",
    "\n",
    "\n",
    "  # batch size and number of batches\n",
    "  batchsize  = 32\n",
    "  numBatches = int(dataT.shape[0]/batchsize)\n",
    "\n",
    "\n",
    "  # loop over epochs (now each epoch goes through all samples)\n",
    "  for epochi in range(numepochs):\n",
    "\n",
    "    \n",
    "    # get a permuted index vector\n",
    "    randidx = np.random.permutation(dataT.shape[0]).astype(int)\n",
    "    \n",
    "    for batchi in range(numBatches):\n",
    "      \n",
    "      # samples to use in this batch\n",
    "      samps2use = range((batchi-1)*batchsize,batchi*batchsize)\n",
    "      \n",
    "\n",
    "      # select those images\n",
    "      X = dataT[randidx[samps2use],:]\n",
    "\n",
    "      # forward pass and loss\n",
    "      yHat = net(X)\n",
    "      loss = lossfun(yHat,X)\n",
    "\n",
    "      # backprop\n",
    "      optimizer.zero_grad()\n",
    "      loss.backward()\n",
    "      optimizer.step()\n",
    "\n",
    "    \n",
    "      # losses in this batch\n",
    "      losses.append( loss.item() )\n",
    "\n",
    "  # end epochs\n",
    "  \n",
    "  # function output\n",
    "  return losses,net"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XpGm9xdQ27Ob"
   },
   "source": [
    "# Run the model and show the results!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "l9pCC1R2p0nu"
   },
   "outputs": [],
   "source": [
    "# train the model (16s)\n",
    "losses,net = function2trainTheModel()\n",
    "print(f'Final loss: {losses[-1]:.4f}')\n",
    "\n",
    "# visualize the losses\n",
    "plt.plot(losses,'.-')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Model loss')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pG7_3tYbp0wm"
   },
   "source": [
    "# Add occlusion to some images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "qw56zhmj87WC"
   },
   "outputs": [],
   "source": [
    "# grab a small set of images\n",
    "X = copy.deepcopy( dataT[:10,:] )\n",
    "\n",
    "# add noise\n",
    "for i in range(X.shape[0]):\n",
    "  \n",
    "  # reshape the image\n",
    "  img = X[i,:].view(28,28)\n",
    "\n",
    "  # occlude random rows or columns\n",
    "  startloc = np.random.choice(range(10,21))\n",
    "  if i%2==0: # even -> horizontal occlusion\n",
    "    img[startloc:startloc+1,:] = 1\n",
    "  else:      # odd -> vertical occlusion\n",
    "    img[:,startloc:startloc+1] = 1\n",
    "\n",
    "\n",
    "\n",
    "# run the samples through the model\n",
    "deOccluded = net(X)\n",
    "\n",
    "\n",
    "# show the noisy images\n",
    "fig,axs = plt.subplots(3,10,figsize=(15,5))\n",
    "\n",
    "for i in range(10):\n",
    "  axs[0,i].imshow(dataT[i,:].view(28,28).detach() ,cmap='gray')\n",
    "  axs[1,i].imshow(X[i,:].view(28,28).detach() ,cmap='gray')\n",
    "  axs[2,i].imshow(deOccluded[i,:].view(28,28).detach() ,cmap='gray')\n",
    "  axs[0,i].set_xticks([]), axs[0,i].set_yticks([])\n",
    "  axs[1,i].set_xticks([]), axs[1,i].set_yticks([])\n",
    "  axs[2,i].set_xticks([]), axs[2,i].set_yticks([])\n",
    "  \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DiCaItS8dCJ3"
   },
   "source": [
    "# Something more quantitative"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ZfH_MkryDd0l"
   },
   "outputs": [],
   "source": [
    "# We can quantify the performance of our \"de-occluder\" by correlating the sample with the original.\n",
    "\n",
    "inOutCorr = np.corrcoef(dataT[9,:].detach(),deOccluded[9,:].detach())\n",
    "\n",
    "# and plot\n",
    "plt.plot(dataT[9,:].detach(),deOccluded[9,:].detach(),'.')\n",
    "plt.xlabel('Original pixel values')\n",
    "plt.ylabel('Reconstructed pixel values')\n",
    "plt.title(f'Correlation r={ inOutCorr[0,1] :.3f}')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "k1llM3w9ERI2"
   },
   "outputs": [],
   "source": [
    "# try again without the zero-valued pixels\n",
    "\n",
    "# extract to variables for convenience\n",
    "orig  = dataT[9,:].detach()\n",
    "recon = deOccluded[9,:].detach()\n",
    "\n",
    "# boolean vector that indicates pixels>0 (with some tolerance)\n",
    "tol = 1e-4\n",
    "nonzeropixels = (orig>tol) & (recon>tol)\n",
    "\n",
    "# then re-compute the correlation\n",
    "inOutCorr = np.corrcoef(orig[nonzeropixels],recon[nonzeropixels])\n",
    "\n",
    "# redraw the previous plot\n",
    "plt.plot(orig[nonzeropixels],recon[nonzeropixels],'.')\n",
    "plt.xlabel('Original pixel values')\n",
    "plt.ylabel('Reconstructed pixel values')\n",
    "plt.title(f'Correlation r={ inOutCorr[0,1] :.3f}')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "9SnUUHPm7xQE"
   },
   "outputs": [],
   "source": [
    "# get data with no occlusion\n",
    "noOcclusion = net(dataT[:10,:])\n",
    "\n",
    "# compare deOccluded-original to noOcclusion-original correlation\n",
    "r = np.zeros((10,2))\n",
    "for i in range(deOccluded.shape[0]):\n",
    "\n",
    "  # pixel selection (note: tolerance defined in previous cell)\n",
    "  nonzeropixels = (dataT[i,:]>tol) & (noOcclusion[i,:]>tol) & (deOccluded[i,:]>tol)\n",
    "\n",
    "  # now compute the correlations\n",
    "  r[i,0] = np.corrcoef(dataT[i,nonzeropixels].detach(),noOcclusion[i,nonzeropixels].detach())[0,1]\n",
    "  r[i,1] = np.corrcoef(dataT[i,nonzeropixels].detach(),deOccluded[i,nonzeropixels].detach())[0,1]\n",
    "\n",
    "\n",
    "# plot the correlation coefficients\n",
    "plt.plot(r,'o',markersize=10)\n",
    "plt.legend(['No occlusion','Occlusion'])\n",
    "plt.xlabel('Sample number')\n",
    "plt.ylabel('Correlation with original')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "-sJ6ROpxkDqg"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Uh28k_l29urR"
   },
   "source": [
    "# Additional explorations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ib3uQtfv9wE2"
   },
   "outputs": [],
   "source": [
    "# 1) Does occlusion affect some numbers more than others? Run the entire dataset through the autoencoder with occluded\n",
    "#    images. Compute the image correlations for each sample. Then compute the average correlation for each number (image\n",
    "#    label). Show the results in a plot. (Bonus: Also compute the standard deviation across correlations and use those\n",
    "#    to draw error bars.) What do the results tell you about the difficulty of fixing occlusions in images?\n",
    "# \n",
    "# 2) Perhaps a correlation coefficient isn't really the best performance metric. Try this: Binarize the images like we \n",
    "#    did in the video \"CodeChallenge: Binarized MNIST images\" (section FFN). Then compute the number of pixels in the \n",
    "#    original and reconstructed images that overlap (hint: try summing them). Make sure your new metric has a possible\n",
    "#    range of 0 (absolutely no overlap) to 1 (perfect overlap). Does this metric seem more consistent with your visual\n",
    "#    intuition?\n",
    "# \n",
    "# 3) But wait a minute, don't we already have a quantitative measure of the similarity between the AE input and output?\n",
    "#    Of course we do -- it's the loss function! Mean-squared error already accounts for zeros because those get ignored\n",
    "#    [zero-valued pixels have MSE=(0-0)**2 ]. In fact, question #2 is kindof a \"rough MSE.\" Take a moment to write down\n",
    "#    the formulas for MSE and correlation, and see whether they are related (hint: the relationship isn't linear because of\n",
    "#    the squared term). Finally, compute MSE on our example occlusion images and compare MSE to correlation empirically\n",
    "#    by making a scatter plot. (Hint 1: Use more than 10 examples to see trends. Hint 2: Consider the signs (+/-).)\n",
    "# \n",
    "# Note about exercises 2&3: MSE really is the best loss function for this problem. The purpose of these exercises is to\n",
    "#    get you thinking critically about autoencoders, loss functions, and the idea of using custom-designed quantitative\n",
    "#    comparisons measures. I hope you find these problems enjoyable and thought-provoking!\n",
    "# "
   ]
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyNcQqSgVvnLbQeD332+SAU6",
   "collapsed_sections": [],
   "name": "DUDL_autoenc_occlusion.ipynb",
   "provenance": [
    {
     "file_id": "19G9gTeBlYPQ-s3VS_3K2bVFtKTP344j6",
     "timestamp": 1619201549381
    },
    {
     "file_id": "1FcEBC0NAESIlHQkv6_85R-XDUKGE8XbM",
     "timestamp": 1619155961717
    },
    {
     "file_id": "1qKgZ8kVcqNgwtBzHbWq5yJH_HqI6DxWW",
     "timestamp": 1617803880910
    },
    {
     "file_id": "15cpyHkJ435B4MqbyGjAH1poN4nCy_DE4",
     "timestamp": 1617737766196
    },
    {
     "file_id": "1OLuWuaFu0hcFgkQ2hh5BqbRuqUZD7XcQ",
     "timestamp": 1617734878578
    },
    {
     "file_id": "1XvzVGJPTJifVh8OpZVB7ykLxyUqYwQ1j",
     "timestamp": 1617196833019
    },
    {
     "file_id": "1bv1_y32e3KEExFKKlPfC3rpw1JxmBr8H",
     "timestamp": 1617124341706
    },
    {
     "file_id": "1GMq8u7KyHB2AE7Teyls9gK1T01OduQSn",
     "timestamp": 1616697516760
    },
    {
     "file_id": "1Ui3kyHim-e0XLgDs2mkBxVlYg7TKYtcg",
     "timestamp": 1616615469755
    },
    {
     "file_id": "1YpHocGI4rApOxIBb1ZghCU5L-hFnv4CK",
     "timestamp": 1616608248670
    }
   ]
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
