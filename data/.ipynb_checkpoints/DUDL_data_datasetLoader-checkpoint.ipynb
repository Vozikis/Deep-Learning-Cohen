{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bhWV8oes-wKR"
   },
   "source": [
    "# COURSE: A deep understanding of deep learning\n",
    "## SECTION: Data matrices and loaders\n",
    "### LECTURE: Anatomy of a torch dataset and dataloader\n",
    "#### TEACHER: Mike X Cohen, sincxpress.com\n",
    "##### COURSE URL: udemy.com/course/deeplearning_x/?couponCode=202212"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "YeuAheYyhdZw"
   },
   "outputs": [],
   "source": [
    "# import libraries\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch.utils.data import DataLoader,TensorDataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vFv_cmvApLb0"
   },
   "source": [
    "# Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "aykKFgznOako"
   },
   "outputs": [],
   "source": [
    "# create some data in numpy\n",
    "\n",
    "nObservations = 100\n",
    "nFeatures = 20\n",
    "\n",
    "data = np.random.randn(nObservations,nFeatures)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "Y_tZ1ymVp0Sf"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Numpy data:\n",
      "<class 'numpy.ndarray'>\n",
      "(100, 20)\n",
      "float64\n",
      " \n",
      "Tensor data:\n",
      "<class 'torch.Tensor'>\n",
      "torch.Size([100, 20])\n",
      "torch.float64\n",
      " \n"
     ]
    }
   ],
   "source": [
    "# Convert to pytorch tensor\n",
    "dataT = torch.tensor( data ) \n",
    "\n",
    "# print out some information\n",
    "print('Numpy data:')\n",
    "print(type(data)) #the type of the data as to what python understands\n",
    "print(data.shape) # numpy -> .shape\n",
    "print(data.dtype) #the type of the objects inside the data\n",
    "print(' ')\n",
    "\n",
    "print('Tensor data:')\n",
    "print(type(dataT))\n",
    "print(dataT.size()) # torch -> .size()\n",
    "print(dataT.dtype)\n",
    "print(' ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "WlSTQeZ2nDDR"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.float32\n",
      "torch.int64\n"
     ]
    }
   ],
   "source": [
    "# Sometimes you need to convert data types\n",
    "#data should be float\n",
    "dataT2 = torch.tensor( data ).float()\n",
    "print(dataT2.dtype)\n",
    "\n",
    "# \"long\" is for ints\n",
    "# We need the labels to be integers \n",
    "dataT3 = torch.tensor( data ).long()\n",
    "print(dataT3.dtype)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "u5fGd4h8mI8a"
   },
   "outputs": [],
   "source": [
    "# Convert tensor into PyTorch Datasets\n",
    "\n",
    "# dataset = TensorDataset(data) # not a tensor!\n",
    "dataset = TensorDataset(dataT)\n",
    "\n",
    "# dataset is a two-element tuple comprising data,labels\n",
    "dataset.tensors[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "wpvxvxBloej3"
   },
   "outputs": [],
   "source": [
    "# Let's try again with labels\n",
    "labels = torch.ceil(torch.linspace(.01,4,nObservations))\n",
    "\n",
    "# transform to an actual matrix (column vector)\n",
    "labels = labels.reshape(( len(labels),1 ))\n",
    "# print( labels )\n",
    "\n",
    "# now make another dataset\n",
    "dataset = TensorDataset(dataT,labels)\n",
    "print( dataset.tensors[0].size() )\n",
    "print( dataset.tensors[1].size() )\n",
    "\n",
    "# for comparison\n",
    "print( np.shape(np.random.randint(5,size=nObservations)) )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wJ-JsNQGpIKT"
   },
   "source": [
    "# DataLoaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "5_kahYcanxBg"
   },
   "outputs": [],
   "source": [
    "# create a dataloader object\n",
    "batchsize = 25\n",
    "dataloader = DataLoader(dataset,batch_size=batchsize)#,shuffle=True,drop_last=True)\n",
    "\n",
    "dataloader.dataset.tensors[0].size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "xu7BF_OTqDj0"
   },
   "outputs": [],
   "source": [
    "# sizes of each batch\n",
    "for dat,labs in dataloader:\n",
    "  print('BATCH INFO:')\n",
    "  print(dat.size())\n",
    "  print(labs.size())\n",
    "  print(' ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "oLkY18PZq-G3"
   },
   "outputs": [],
   "source": [
    "# inspect the labels\n",
    "for dat,labs in dataloader:\n",
    "  print(labs.T)\n",
    "  print(' ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "zyeJ6mjjre6p"
   },
   "outputs": [],
   "source": [
    "# try again with shuffling (shuffling happens during iterations)\n",
    "# dataloader = DataLoader(dataset,batch_size=batchsize,shuffle=True)\n",
    "\n",
    "for dat,labs in dataloader:\n",
    "  print(labs.T)\n",
    "  print(' ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "S236TLLury42"
   },
   "outputs": [],
   "source": [
    "# To get only one batch (e.g., for testing)\n",
    "\n",
    "dat,labs = next(iter(dataloader))\n",
    "\n",
    "labs"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyMDTrf0kN4swdushiJqB9Kn",
   "collapsed_sections": [],
   "name": "DUDL_data_datasetLoader.ipynb",
   "provenance": [
    {
     "file_id": "1t1AgKE-GpPPUcjGZyTF_Ie1Q9XWA3xn-",
     "timestamp": 1618172332728
    },
    {
     "file_id": "1qKgZ8kVcqNgwtBzHbWq5yJH_HqI6DxWW",
     "timestamp": 1617803880910
    },
    {
     "file_id": "15cpyHkJ435B4MqbyGjAH1poN4nCy_DE4",
     "timestamp": 1617737766196
    },
    {
     "file_id": "1OLuWuaFu0hcFgkQ2hh5BqbRuqUZD7XcQ",
     "timestamp": 1617734878578
    },
    {
     "file_id": "1XvzVGJPTJifVh8OpZVB7ykLxyUqYwQ1j",
     "timestamp": 1617196833019
    },
    {
     "file_id": "1bv1_y32e3KEExFKKlPfC3rpw1JxmBr8H",
     "timestamp": 1617124341706
    },
    {
     "file_id": "1GMq8u7KyHB2AE7Teyls9gK1T01OduQSn",
     "timestamp": 1616697516760
    },
    {
     "file_id": "1Ui3kyHim-e0XLgDs2mkBxVlYg7TKYtcg",
     "timestamp": 1616615469755
    },
    {
     "file_id": "1YpHocGI4rApOxIBb1ZghCU5L-hFnv4CK",
     "timestamp": 1616608248670
    }
   ]
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
