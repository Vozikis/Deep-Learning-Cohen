{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bhWV8oes-wKR"
   },
   "source": [
    "# COURSE: A deep understanding of deep learning\n",
    "## SECTION: Generative adversarial networks\n",
    "### LECTURE: Linear GAN with MNIST\n",
    "#### TEACHER: Mike X Cohen, sincxpress.com\n",
    "##### COURSE URL: udemy.com/course/deeplearning_x/?couponCode=202212"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-02-08T09:00:22.773852Z",
     "start_time": "2023-02-08T09:00:21.654523Z"
    },
    "id": "YeuAheYyhdZw"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/f2/gq8xgm9x491cqwtct_tgpy0h0000gn/T/ipykernel_99843/357070595.py:12: DeprecationWarning: `set_matplotlib_formats` is deprecated since IPython 7.23, directly use `matplotlib_inline.backend_inline.set_matplotlib_formats()`\n",
      "  display.set_matplotlib_formats('svg')\n"
     ]
    }
   ],
   "source": [
    "# import libraries\n",
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "import sys\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython import display\n",
    "display.set_matplotlib_formats('svg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-02-08T09:00:25.985165Z",
     "start_time": "2023-02-08T09:00:25.975515Z"
    },
    "id": "lpcmh-V8hIlw"
   },
   "outputs": [],
   "source": [
    "device = torch.device('mps' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vpUeQWVfBJbY"
   },
   "source": [
    "# Import the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-02-08T09:02:17.140225Z",
     "start_time": "2023-02-08T09:02:16.616528Z"
    },
    "id": "yfZKI3EXBHL5"
   },
   "outputs": [],
   "source": [
    "# import dataset (comes with colab!)\n",
    "data = np.loadtxt(open('mnist_train_small.csv','rb'),delimiter=',')\n",
    "\n",
    "# don't need the labels here\n",
    "data = data[:,1:]\n",
    "\n",
    "#we want the data to be in the [-1,1] area because the model trains better in this area\n",
    "# normalize the data to a range of [-1 1] (b/c tanh output)\n",
    "dataNorm = data / np.max(data)\n",
    "dataNorm = 2*dataNorm - 1\n",
    "\n",
    "# convert to tensor\n",
    "dataT = torch.tensor( dataNorm ).float()\n",
    "\n",
    "# no dataloaders!\n",
    "batchsize = 100\n",
    "#we will just randomly draw batches of 100 from dataT."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7vvglaJyCMpO"
   },
   "source": [
    "# Create classes for the discriminator and generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-02-08T09:02:46.904085Z",
     "start_time": "2023-02-08T09:02:46.883089Z"
    },
    "id": "UT-TyZZDK9-9"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.4758],\n",
       "        [0.4985],\n",
       "        [0.5057],\n",
       "        [0.4924],\n",
       "        [0.4845],\n",
       "        [0.4732],\n",
       "        [0.5014],\n",
       "        [0.4777],\n",
       "        [0.4677],\n",
       "        [0.4480]], grad_fn=<SigmoidBackward0>)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class discriminatorNet(nn.Module):\n",
    "  def __init__(self):\n",
    "    super().__init__()\n",
    "    \n",
    "    self.fc1 = nn.Linear(28*28,256)\n",
    "    self.fc2 = nn.Linear(256,256)\n",
    "    self.out = nn.Linear(256,1)\n",
    "\n",
    "  def forward(self,x):\n",
    "    x = F.leaky_relu( self.fc1(x) )\n",
    "    x = F.leaky_relu( self.fc2(x) )\n",
    "    x = self.out(x)\n",
    "    return torch.sigmoid( x )\n",
    "\n",
    "dnet = discriminatorNet()\n",
    "y = dnet(torch.randn(10,784))\n",
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-02-08T09:03:04.575595Z",
     "start_time": "2023-02-08T09:03:04.464742Z"
    },
    "id": "alVVPOJiLTHB"
   },
   "outputs": [
    {
     "data": {
      "image/svg+xml": [
       "<?xml version=\"1.0\" encoding=\"utf-8\" standalone=\"no\"?>\n",
       "<!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\"\n",
       "  \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\">\n",
       "<svg xmlns:xlink=\"http://www.w3.org/1999/xlink\" width=\"300.237pt\" height=\"297.190125pt\" viewBox=\"0 0 300.237 297.190125\" xmlns=\"http://www.w3.org/2000/svg\" version=\"1.1\">\n",
       " <metadata>\n",
       "  <rdf:RDF xmlns:dc=\"http://purl.org/dc/elements/1.1/\" xmlns:cc=\"http://creativecommons.org/ns#\" xmlns:rdf=\"http://www.w3.org/1999/02/22-rdf-syntax-ns#\">\n",
       "   <cc:Work>\n",
       "    <dc:type rdf:resource=\"http://purl.org/dc/dcmitype/StillImage\"/>\n",
       "    <dc:date>2023-02-08T11:03:04.552756</dc:date>\n",
       "    <dc:format>image/svg+xml</dc:format>\n",
       "    <dc:creator>\n",
       "     <cc:Agent>\n",
       "      <dc:title>Matplotlib v3.6.0, https://matplotlib.org/</dc:title>\n",
       "     </cc:Agent>\n",
       "    </dc:creator>\n",
       "   </cc:Work>\n",
       "  </rdf:RDF>\n",
       " </metadata>\n",
       " <defs>\n",
       "  <style type=\"text/css\">*{stroke-linejoin: round; stroke-linecap: butt}</style>\n",
       " </defs>\n",
       " <g id=\"figure_1\">\n",
       "  <g id=\"patch_1\">\n",
       "   <path d=\"M -0 297.190125 \n",
       "L 300.237 297.190125 \n",
       "L 300.237 0 \n",
       "L -0 0 \n",
       "z\n",
       "\" style=\"fill: #ffffff\"/>\n",
       "  </g>\n",
       "  <g id=\"axes_1\">\n",
       "   <g id=\"patch_2\">\n",
       "    <path d=\"M 26.925 273.312 \n",
       "L 293.037 273.312 \n",
       "L 293.037 7.2 \n",
       "L 26.925 7.2 \n",
       "z\n",
       "\" style=\"fill: #ffffff\"/>\n",
       "   </g>\n",
       "   <g clip-path=\"url(#pec7447fa3d)\">\n",
       "    <image xlink:href=\"data:image/png;base64,\n",
       "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\" id=\"imageb8a1f82ba0\" transform=\"scale(1 -1) translate(0 -266.4)\" x=\"26.925\" y=\"-6.912\" width=\"266.4\" height=\"266.4\"/>\n",
       "   </g>\n",
       "   <g id=\"matplotlib.axis_1\">\n",
       "    <g id=\"xtick_1\">\n",
       "     <g id=\"line2d_1\">\n",
       "      <defs>\n",
       "       <path id=\"m5e61240500\" d=\"M 0 0 \n",
       "L 0 3.5 \n",
       "\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n",
       "      </defs>\n",
       "      <g>\n",
       "       <use xlink:href=\"#m5e61240500\" x=\"31.677\" y=\"273.312\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "     <g id=\"text_1\">\n",
       "      <!-- 0 -->\n",
       "      <g transform=\"translate(28.49575 287.910437) scale(0.1 -0.1)\">\n",
       "       <defs>\n",
       "        <path id=\"DejaVuSans-30\" d=\"M 2034 4250 \n",
       "Q 1547 4250 1301 3770 \n",
       "Q 1056 3291 1056 2328 \n",
       "Q 1056 1369 1301 889 \n",
       "Q 1547 409 2034 409 \n",
       "Q 2525 409 2770 889 \n",
       "Q 3016 1369 3016 2328 \n",
       "Q 3016 3291 2770 3770 \n",
       "Q 2525 4250 2034 4250 \n",
       "z\n",
       "M 2034 4750 \n",
       "Q 2819 4750 3233 4129 \n",
       "Q 3647 3509 3647 2328 \n",
       "Q 3647 1150 3233 529 \n",
       "Q 2819 -91 2034 -91 \n",
       "Q 1250 -91 836 529 \n",
       "Q 422 1150 422 2328 \n",
       "Q 422 3509 836 4129 \n",
       "Q 1250 4750 2034 4750 \n",
       "z\n",
       "\" transform=\"scale(0.015625)\"/>\n",
       "       </defs>\n",
       "       <use xlink:href=\"#DejaVuSans-30\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"xtick_2\">\n",
       "     <g id=\"line2d_2\">\n",
       "      <g>\n",
       "       <use xlink:href=\"#m5e61240500\" x=\"79.197\" y=\"273.312\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "     <g id=\"text_2\">\n",
       "      <!-- 5 -->\n",
       "      <g transform=\"translate(76.01575 287.910437) scale(0.1 -0.1)\">\n",
       "       <defs>\n",
       "        <path id=\"DejaVuSans-35\" d=\"M 691 4666 \n",
       "L 3169 4666 \n",
       "L 3169 4134 \n",
       "L 1269 4134 \n",
       "L 1269 2991 \n",
       "Q 1406 3038 1543 3061 \n",
       "Q 1681 3084 1819 3084 \n",
       "Q 2600 3084 3056 2656 \n",
       "Q 3513 2228 3513 1497 \n",
       "Q 3513 744 3044 326 \n",
       "Q 2575 -91 1722 -91 \n",
       "Q 1428 -91 1123 -41 \n",
       "Q 819 9 494 109 \n",
       "L 494 744 \n",
       "Q 775 591 1075 516 \n",
       "Q 1375 441 1709 441 \n",
       "Q 2250 441 2565 725 \n",
       "Q 2881 1009 2881 1497 \n",
       "Q 2881 1984 2565 2268 \n",
       "Q 2250 2553 1709 2553 \n",
       "Q 1456 2553 1204 2497 \n",
       "Q 953 2441 691 2322 \n",
       "L 691 4666 \n",
       "z\n",
       "\" transform=\"scale(0.015625)\"/>\n",
       "       </defs>\n",
       "       <use xlink:href=\"#DejaVuSans-35\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"xtick_3\">\n",
       "     <g id=\"line2d_3\">\n",
       "      <g>\n",
       "       <use xlink:href=\"#m5e61240500\" x=\"126.717\" y=\"273.312\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "     <g id=\"text_3\">\n",
       "      <!-- 10 -->\n",
       "      <g transform=\"translate(120.3545 287.910437) scale(0.1 -0.1)\">\n",
       "       <defs>\n",
       "        <path id=\"DejaVuSans-31\" d=\"M 794 531 \n",
       "L 1825 531 \n",
       "L 1825 4091 \n",
       "L 703 3866 \n",
       "L 703 4441 \n",
       "L 1819 4666 \n",
       "L 2450 4666 \n",
       "L 2450 531 \n",
       "L 3481 531 \n",
       "L 3481 0 \n",
       "L 794 0 \n",
       "L 794 531 \n",
       "z\n",
       "\" transform=\"scale(0.015625)\"/>\n",
       "       </defs>\n",
       "       <use xlink:href=\"#DejaVuSans-31\"/>\n",
       "       <use xlink:href=\"#DejaVuSans-30\" x=\"63.623047\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"xtick_4\">\n",
       "     <g id=\"line2d_4\">\n",
       "      <g>\n",
       "       <use xlink:href=\"#m5e61240500\" x=\"174.237\" y=\"273.312\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "     <g id=\"text_4\">\n",
       "      <!-- 15 -->\n",
       "      <g transform=\"translate(167.8745 287.910437) scale(0.1 -0.1)\">\n",
       "       <use xlink:href=\"#DejaVuSans-31\"/>\n",
       "       <use xlink:href=\"#DejaVuSans-35\" x=\"63.623047\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"xtick_5\">\n",
       "     <g id=\"line2d_5\">\n",
       "      <g>\n",
       "       <use xlink:href=\"#m5e61240500\" x=\"221.757\" y=\"273.312\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "     <g id=\"text_5\">\n",
       "      <!-- 20 -->\n",
       "      <g transform=\"translate(215.3945 287.910437) scale(0.1 -0.1)\">\n",
       "       <defs>\n",
       "        <path id=\"DejaVuSans-32\" d=\"M 1228 531 \n",
       "L 3431 531 \n",
       "L 3431 0 \n",
       "L 469 0 \n",
       "L 469 531 \n",
       "Q 828 903 1448 1529 \n",
       "Q 2069 2156 2228 2338 \n",
       "Q 2531 2678 2651 2914 \n",
       "Q 2772 3150 2772 3378 \n",
       "Q 2772 3750 2511 3984 \n",
       "Q 2250 4219 1831 4219 \n",
       "Q 1534 4219 1204 4116 \n",
       "Q 875 4013 500 3803 \n",
       "L 500 4441 \n",
       "Q 881 4594 1212 4672 \n",
       "Q 1544 4750 1819 4750 \n",
       "Q 2544 4750 2975 4387 \n",
       "Q 3406 4025 3406 3419 \n",
       "Q 3406 3131 3298 2873 \n",
       "Q 3191 2616 2906 2266 \n",
       "Q 2828 2175 2409 1742 \n",
       "Q 1991 1309 1228 531 \n",
       "z\n",
       "\" transform=\"scale(0.015625)\"/>\n",
       "       </defs>\n",
       "       <use xlink:href=\"#DejaVuSans-32\"/>\n",
       "       <use xlink:href=\"#DejaVuSans-30\" x=\"63.623047\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"xtick_6\">\n",
       "     <g id=\"line2d_6\">\n",
       "      <g>\n",
       "       <use xlink:href=\"#m5e61240500\" x=\"269.277\" y=\"273.312\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "     <g id=\"text_6\">\n",
       "      <!-- 25 -->\n",
       "      <g transform=\"translate(262.9145 287.910437) scale(0.1 -0.1)\">\n",
       "       <use xlink:href=\"#DejaVuSans-32\"/>\n",
       "       <use xlink:href=\"#DejaVuSans-35\" x=\"63.623047\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "    </g>\n",
       "   </g>\n",
       "   <g id=\"matplotlib.axis_2\">\n",
       "    <g id=\"ytick_1\">\n",
       "     <g id=\"line2d_7\">\n",
       "      <defs>\n",
       "       <path id=\"m7015a2f798\" d=\"M 0 0 \n",
       "L -3.5 0 \n",
       "\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n",
       "      </defs>\n",
       "      <g>\n",
       "       <use xlink:href=\"#m7015a2f798\" x=\"26.925\" y=\"11.952\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "     <g id=\"text_7\">\n",
       "      <!-- 0 -->\n",
       "      <g transform=\"translate(13.5625 15.751219) scale(0.1 -0.1)\">\n",
       "       <use xlink:href=\"#DejaVuSans-30\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"ytick_2\">\n",
       "     <g id=\"line2d_8\">\n",
       "      <g>\n",
       "       <use xlink:href=\"#m7015a2f798\" x=\"26.925\" y=\"59.472\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "     <g id=\"text_8\">\n",
       "      <!-- 5 -->\n",
       "      <g transform=\"translate(13.5625 63.271219) scale(0.1 -0.1)\">\n",
       "       <use xlink:href=\"#DejaVuSans-35\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"ytick_3\">\n",
       "     <g id=\"line2d_9\">\n",
       "      <g>\n",
       "       <use xlink:href=\"#m7015a2f798\" x=\"26.925\" y=\"106.992\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "     <g id=\"text_9\">\n",
       "      <!-- 10 -->\n",
       "      <g transform=\"translate(7.2 110.791219) scale(0.1 -0.1)\">\n",
       "       <use xlink:href=\"#DejaVuSans-31\"/>\n",
       "       <use xlink:href=\"#DejaVuSans-30\" x=\"63.623047\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"ytick_4\">\n",
       "     <g id=\"line2d_10\">\n",
       "      <g>\n",
       "       <use xlink:href=\"#m7015a2f798\" x=\"26.925\" y=\"154.512\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "     <g id=\"text_10\">\n",
       "      <!-- 15 -->\n",
       "      <g transform=\"translate(7.2 158.311219) scale(0.1 -0.1)\">\n",
       "       <use xlink:href=\"#DejaVuSans-31\"/>\n",
       "       <use xlink:href=\"#DejaVuSans-35\" x=\"63.623047\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"ytick_5\">\n",
       "     <g id=\"line2d_11\">\n",
       "      <g>\n",
       "       <use xlink:href=\"#m7015a2f798\" x=\"26.925\" y=\"202.032\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "     <g id=\"text_11\">\n",
       "      <!-- 20 -->\n",
       "      <g transform=\"translate(7.2 205.831219) scale(0.1 -0.1)\">\n",
       "       <use xlink:href=\"#DejaVuSans-32\"/>\n",
       "       <use xlink:href=\"#DejaVuSans-30\" x=\"63.623047\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"ytick_6\">\n",
       "     <g id=\"line2d_12\">\n",
       "      <g>\n",
       "       <use xlink:href=\"#m7015a2f798\" x=\"26.925\" y=\"249.552\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "     <g id=\"text_12\">\n",
       "      <!-- 25 -->\n",
       "      <g transform=\"translate(7.2 253.351219) scale(0.1 -0.1)\">\n",
       "       <use xlink:href=\"#DejaVuSans-32\"/>\n",
       "       <use xlink:href=\"#DejaVuSans-35\" x=\"63.623047\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "    </g>\n",
       "   </g>\n",
       "   <g id=\"patch_3\">\n",
       "    <path d=\"M 26.925 273.312 \n",
       "L 26.925 7.2 \n",
       "\" style=\"fill: none; stroke: #000000; stroke-width: 0.8; stroke-linejoin: miter; stroke-linecap: square\"/>\n",
       "   </g>\n",
       "   <g id=\"patch_4\">\n",
       "    <path d=\"M 293.037 273.312 \n",
       "L 293.037 7.2 \n",
       "\" style=\"fill: none; stroke: #000000; stroke-width: 0.8; stroke-linejoin: miter; stroke-linecap: square\"/>\n",
       "   </g>\n",
       "   <g id=\"patch_5\">\n",
       "    <path d=\"M 26.925 273.312 \n",
       "L 293.037 273.312 \n",
       "\" style=\"fill: none; stroke: #000000; stroke-width: 0.8; stroke-linejoin: miter; stroke-linecap: square\"/>\n",
       "   </g>\n",
       "   <g id=\"patch_6\">\n",
       "    <path d=\"M 26.925 7.2 \n",
       "L 293.037 7.2 \n",
       "\" style=\"fill: none; stroke: #000000; stroke-width: 0.8; stroke-linejoin: miter; stroke-linecap: square\"/>\n",
       "   </g>\n",
       "  </g>\n",
       " </g>\n",
       " <defs>\n",
       "  <clipPath id=\"pec7447fa3d\">\n",
       "   <rect x=\"26.925\" y=\"7.2\" width=\"266.112\" height=\"266.112\"/>\n",
       "  </clipPath>\n",
       " </defs>\n",
       "</svg>\n"
      ],
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "class generatorNet(nn.Module):\n",
    "  def __init__(self):\n",
    "    super().__init__()\n",
    "    \n",
    "    self.fc1 = nn.Linear(64,256)\n",
    "    self.fc2 = nn.Linear(256,256)\n",
    "    self.out = nn.Linear(256,784)\n",
    "\n",
    "  def forward(self,x):\n",
    "    x = F.leaky_relu( self.fc1(x) )\n",
    "    x = F.leaky_relu( self.fc2(x) )\n",
    "    x = self.out(x)\n",
    "    return torch.tanh( x )\n",
    "\n",
    "\n",
    "gnet = generatorNet()\n",
    "y = gnet(torch.randn(10,64))\n",
    "plt.imshow(y[0,:].detach().squeeze().view(28,28));"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bBsOOqcX_LvO"
   },
   "source": [
    "# Train the models!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "SFDbnRqeCPqy"
   },
   "outputs": [],
   "source": [
    "# loss function (same for both phases of training)\n",
    "lossfun = nn.BCELoss()\n",
    "\n",
    "# create instances of the models\n",
    "dnet = discriminatorNet().to(device)\n",
    "gnet = generatorNet().to(device)\n",
    "\n",
    "# optimizers (same algo but different variables b/c different parameters)\n",
    "d_optimizer = torch.optim.Adam(dnet.parameters(), lr=.0003)\n",
    "g_optimizer = torch.optim.Adam(gnet.parameters(), lr=.0003)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "83Ju8fDuUTBg"
   },
   "outputs": [],
   "source": [
    "# this cell takes ~3 mins with 50k epochs\n",
    "num_epochs = 50000\n",
    "\n",
    "losses  = np.zeros((num_epochs,2))\n",
    "disDecs = np.zeros((num_epochs,2)) # disDecs = discriminator decisions\n",
    "\n",
    "for epochi in range(num_epochs):\n",
    "    \n",
    "  # create minibatches of REAL and FAKE images \n",
    "  randidx     = torch.randint(dataT.shape[0],(batchsize,))\n",
    "  real_images = dataT[randidx,:].to(device)\n",
    "  fake_images = gnet( torch.randn(batchsize,64).to(device) ) # output of generator\n",
    "\n",
    "\n",
    "  # labels used for real and fake images\n",
    "  real_labels = torch.ones(batchsize,1).to(device)\n",
    "  fake_labels = torch.zeros(batchsize,1).to(device)\n",
    "\n",
    "\n",
    "\n",
    "  ### ---------------- Train the discriminator ---------------- ###\n",
    "\n",
    "  # forward pass and loss for REAL pictures\n",
    "  pred_real   = dnet(real_images)              # REAL images into discriminator\n",
    "  d_loss_real = lossfun(pred_real,real_labels) # all labels are 1\n",
    "  \n",
    "  # forward pass and loss for FAKE pictures\n",
    "  pred_fake   = dnet(fake_images)              # FAKE images into discriminator\n",
    "  d_loss_fake = lossfun(pred_fake,fake_labels) # all labels are 0\n",
    "  \n",
    "  # collect loss (using combined losses)\n",
    "  d_loss = d_loss_real + d_loss_fake\n",
    "  losses[epochi,0]  = d_loss.item()\n",
    "  disDecs[epochi,0] = torch.mean((pred_real>.5).float()).detach()\n",
    "\n",
    "  # backprop\n",
    "  d_optimizer.zero_grad()\n",
    "  d_loss.backward()\n",
    "  d_optimizer.step()\n",
    "\n",
    "  \n",
    "  \n",
    "\n",
    "  ### ---------------- Train the generator ---------------- ###\n",
    "\n",
    "  # create fake images and compute loss\n",
    "  fake_images = gnet( torch.randn(batchsize,64).to(device) )\n",
    "  pred_fake   = dnet(fake_images)\n",
    "  \n",
    "  # compute and collect loss and accuracy\n",
    "  g_loss = lossfun(pred_fake,real_labels)\n",
    "  losses[epochi,1]  = g_loss.item()\n",
    "  disDecs[epochi,1] = torch.mean((pred_fake>.5).float()).detach()\n",
    "  \n",
    "  # backprop\n",
    "  g_optimizer.zero_grad()\n",
    "  g_loss.backward()\n",
    "  g_optimizer.step()\n",
    "\n",
    "  \n",
    "  # print out a status message\n",
    "  if (epochi+1)%500==0:\n",
    "    msg = f'Finished epoch {epochi+1}/{num_epochs}'\n",
    "    sys.stdout.write('\\r' + msg)\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "1C0qAf9kN7mi"
   },
   "outputs": [],
   "source": [
    "fig,ax = plt.subplots(1,3,figsize=(18,5))\n",
    "\n",
    "ax[0].plot(losses)\n",
    "ax[0].set_xlabel('Epochs')\n",
    "ax[0].set_ylabel('Loss')\n",
    "ax[0].set_title('Model loss')\n",
    "ax[0].legend(['Discrimator','Generator'])\n",
    "# ax[0].set_xlim([4000,5000])\n",
    "\n",
    "ax[1].plot(losses[::5,0],losses[::5,1],'k.',alpha=.1)\n",
    "ax[1].set_xlabel('Discriminator loss')\n",
    "ax[1].set_ylabel('Generator loss')\n",
    "\n",
    "ax[2].plot(disDecs)\n",
    "ax[2].set_xlabel('Epochs')\n",
    "ax[2].set_ylabel('Probablity (\"real\")')\n",
    "ax[2].set_title('Discriminator output')\n",
    "ax[2].legend(['Real','Fake'])\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ElnXz0ZkS8Yc"
   },
   "source": [
    "# Let's see some fake digits!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "AzCz1UqGCP8T"
   },
   "outputs": [],
   "source": [
    "# generate the images from the generator network\n",
    "gnet.eval()\n",
    "fake_data = gnet(torch.randn(12,64).to(device)).cpu()\n",
    "\n",
    "# and visualize...\n",
    "fig,axs = plt.subplots(3,4,figsize=(8,6))\n",
    "for i,ax in enumerate(axs.flatten()):\n",
    "  ax.imshow(fake_data[i,:,].detach().view(28,28),cmap='gray')\n",
    "  ax.axis('off')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "pU-I5tvmCP-6"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-Q1Cx6X9i0H-"
   },
   "source": [
    "# Additional explorations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "IfVbtROJi0K2"
   },
   "outputs": [],
   "source": [
    "# 1) I tried adding batch normalization to the models, but the results weren't that nice. Can you guess why? Try adding\n",
    "#    batchnorm after each layer (except the output) and observe the effects. Can you explain why the results are the\n",
    "#    way they are? (Note: batchnorm becomes important in deeper CNN GANs.)\n",
    "# \n",
    "# 2) Re-running the same code to show the fake images returns different digits each time. Fix PyTorch's random seed so \n",
    "#    that the random numbers are identical each time you run the code. Are the images still different on multiple runs?\n",
    "# \n",
    "# 3) To see how the generator is progressing, you can create some images during training. Here's what to do: (1) put the\n",
    "#    image-generation code above inside a function. (2) Modify that function so that the figure is saved to a file.\n",
    "#    (3) Modify the training function so that it calls the plotting function every 5000 epochs (or whatever resolution\n",
    "#    you want). Then you can see how the images look more like digits as the generator model learns!\n",
    "# \n",
    "# 4) GANs can be quite sensitive to the learning rate, because you are training two different but interacting networks\n",
    "#    at the same time. Usually a good strategy is to have a very small learning rate and train for a long time. But don't\n",
    "#    take my advice -- try a much larger learning rate for a shorter period of time, and see what happens!\n",
    "# "
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "authorship_tag": "ABX9TyPlzEW5LV2osq7FEpHisaLq",
   "collapsed_sections": [],
   "name": "DUDL_GAN_MNIST.ipynb",
   "provenance": [
    {
     "file_id": "1W9fGz1EYzDhtHHpBYU6M2fEpi9Q1uXez",
     "timestamp": 1620754493662
    }
   ]
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
